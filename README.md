# Word2Vec
Understanding the Concepts of Word Embeddings and Word2Vec Algorithm

This NoteBook is meant to Demonstrate the Creation of the Word2Vec Model using two methods
1. By Creating the Word2Vec Model using the Custom Dataset collected from the Kaggle Website Which consists of all the news article titles and other features the link to the Dataset is https://www.kaggle.com/datasets/rootuser/worldnews-on-reddit
2. BY Using a PreBuilt Model Created by Google in the Year 2013 using 3 Billion words which has a Greater accuracy and can take up to a large amount of resources to build it again so we directly use it. The link to the model is https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g

This Word2Vec Demonstration is performed using the gensim library.
